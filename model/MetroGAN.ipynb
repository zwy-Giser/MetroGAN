{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea997968",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MetroGAN\n",
    "This code is for 128*128 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5a47c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "import neptune.new as neptune\n",
    "import functools\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.nn.utils.spectral_norm as spectral_norm\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a945035-305e-4e42-ae2a-d21152c51ebd",
   "metadata": {},
   "source": [
    "### neptune init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e39efc-2c70-4a03-97c7-6a770c73511b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GPU usage configuration\n",
    "cuda_id = 0\n",
    "torch.cuda.set_device(cuda_id)\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "device = torch.device(\"cuda:{}\".format(cuda_id) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# neptune block\n",
    "neptune_log = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a330771",
   "metadata": {},
   "source": [
    "## dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4222d87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, transforms_=None, mode=\"train\"):\n",
    "        \"\"\"\n",
    "        :param root: root path of the dataset\n",
    "        :param transforms_: transforms of the data\n",
    "        :param mode: \"train\"/\"test\". In test mode, the name of the city will be record and the inputs will be record separately.\n",
    "        \"\"\"\n",
    "        self.mode=mode\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        #self.pop_files = sorted(glob.glob(os.path.join(root, \"population resize\") + \"/*.*\"))\n",
    "        self.light_files = sorted(glob.glob(os.path.join(root, \"NTL\") + \"/*.*\"))\n",
    "        self.water_files = sorted(glob.glob(os.path.join(root, \"Water\") + \"/*.*\"))\n",
    "        self.build_files = sorted(glob.glob(os.path.join(root, \"Built-up_area\") + \"/*.*\"))\n",
    "        self.dem_files = sorted(glob.glob(os.path.join(root, \"DEM\") + \"/*.*\"))\n",
    "        # print(len(self.light_files),(os.path.join(root,\"population resize/population resize\") + \"/*.*\"))\n",
    "        if mode == \"test\":\n",
    "            self.cities_name = sorted(glob.glob(os.path.join(root, \"DEM\") + \"/*.*\"))\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        index = index % len(self.dem_files)\n",
    "        #img_pop = self.transform((torch.as_tensor(np.array(Image.open(self.pop_files[index])), dtype=torch.float))*2-1)\n",
    "        img_light = (torch.as_tensor(np.array(Image.open(self.light_files[index])), dtype=torch.float)) *2 -1\n",
    "        img_water = (torch.as_tensor(np.array(Image.open(self.water_files[index])), dtype=torch.float)) / 127.5-1\n",
    "\n",
    "        img_build_ori = (torch.as_tensor(np.array(Image.open(self.build_files[index])), dtype=torch.float)) / 127.5-1\n",
    "        img_build = self.transform(img_build_ori.unsqueeze(0))\n",
    "        \n",
    "        img_dem = (torch.as_tensor(np.array(Image.open(self.dem_files[index])), dtype=torch.float) *2-1)\n",
    "        \n",
    "        input_img = torch.stack([img_dem,img_light,img_water], dim=0)\n",
    "        if self.mode == \"test\":\n",
    "            city_name = self.cities_name[index]\n",
    "            return {\"input_img\": input_img,\n",
    "                    \"label\": img_build,\n",
    "                    \"mask\": img_water.unsqueeze(0),\n",
    "                    \"dem\": img_dem.unsqueeze(0),\n",
    "                    \"name\": city_name[city_name.rindex('/')+1:city_name.rindex('.')]}\n",
    "        else:\n",
    "            return {\"input_img\": input_img,\n",
    "                    \"label\": img_build,\n",
    "                    \"mask\": img_water.unsqueeze(0)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dem_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b6ee1d",
   "metadata": {},
   "source": [
    "## parameter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93710d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# neptune type parameters\n",
    "parameters = {\n",
    "    'img_size':128,\n",
    "    'start_epoch': 0,\n",
    "    'n_epochs': 400,\n",
    "    'dataset_name': \"global_city_dataset\",\n",
    "    'batch_size':64,\n",
    "    'g_lr': 0.0004,\n",
    "    'd_lr':0.0004,\n",
    "    'scheduler':\"cosine\",\n",
    "    'gan_loss':\"mse\",\n",
    "    'decay_epoch': 0,\n",
    "    'optimizer': 'adam',\n",
    "    'b1': 0.5,\n",
    "    'b2': 0.999,\n",
    "    'input_channels': 3,\n",
    "    'output_channels': 1,\n",
    "    'input_path': \"../multi-year_dataset/train\",\n",
    "    'test_path': \"../multi-year_dataset/validate\",\n",
    "    'pixel_lamda': 30,\n",
    "    'ngf': 64,\n",
    "    'sample_interval': 50,\n",
    "    'checkpoint_interval': 50,\n",
    "    'n_cpu': 8,\n",
    "    'debug':False,\n",
    "    'pretrain':False,\n",
    "    'pretrain_save':True,\n",
    "    'load_pretrain' : False,\n",
    "}\n",
    "if neptune_log:\n",
    "    run['model/parameters'] = parameters\n",
    "    os.makedirs(\"images/%s\" % run['sys/id'].fetch(), exist_ok=True)\n",
    "    os.makedirs(\"saved_models/%s\" % run['sys/id'].fetch(), exist_ok=True)\n",
    "print(parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1b5472",
   "metadata": {
    "tags": []
   },
   "source": [
    "## tool functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f14bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The function to initialize the model\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "def ShowResults(generator, dataloader_test, step, mode=\"train\"):\n",
    "    generator.eval()\n",
    "    for j, test_batch in enumerate(dataloader_test):\n",
    "        if j == 1:\n",
    "            test_input_img = test_batch[\"input_img\"].cuda()\n",
    "            test_label = 0.5* test_batch[\"label\"]+0.5\n",
    "            with torch.no_grad():\n",
    "                fake = 0.5* generator(test_input_img, step, 1).detach().cpu()+0.5\n",
    "                imgs = torch.cat((fake, test_label), dim=0)\n",
    "                if step == 5:\n",
    "                    imgs = torch.cat(\n",
    "                        (imgs,\n",
    "                         0.5+0.5*(test_input_img.cpu()[:, 1, :, :].unsqueeze(1)),\n",
    "                         0.5+0.5*(test_input_img.cpu()[:, 0, :, :].unsqueeze(1)),\n",
    "                         0.5+0.5*(test_input_img.cpu()[:, 2, :, :].unsqueeze(1))),\n",
    "                        dim=0)\n",
    "                fig = plt.figure(dpi=200.0)\n",
    "                plt.imshow(np.transpose(vutils.make_grid(imgs, padding=2, normalize=False,pad_value=1.0), (1, 2, 0)))\n",
    "                plt.axis(\"off\")\n",
    "                if neptune_log:\n",
    "                    if mode==\"pretrain\":\n",
    "                        run[\"city-fig/pretrain_{}\".format(epoch)].upload(fig)\n",
    "                    elif mode==\"train\":\n",
    "                        run[\"city-fig/{}\".format(epoch)].upload(fig)\n",
    "                    else:\n",
    "                        assert False\n",
    "                    run[\"city-figs\"].log(fig)\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "    generator.train()\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer, lr_policy):\n",
    "    \"\"\"\n",
    "    The fuction to choose learning rate scheduler\n",
    "    :param optimizer: the optimizer of the network\n",
    "    :param lr_policy: a string that indicate lr policy\n",
    "    :return: the scheduler\n",
    "    \"\"\"\n",
    "    if lr_policy == 'linear':\n",
    "        def lambda_rule(epoch):\n",
    "            lr_l = 1.0 - max(0, epoch - 100) / float(parameters[\"n_epochs\"]-99)\n",
    "            return lr_l\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "    elif lr_policy == 'step':\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "    elif lr_policy == 'plateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n",
    "    elif lr_policy == 'cosine':\n",
    "        #scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=parameters[\"n_epochs\"], eta_min=0)\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=2,T_mult=2)\n",
    "    else:\n",
    "        return NotImplementedError('learning rate policy [%s] is not implemented', opt.lr_policy)\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d6d774",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68180e06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weighted scaled conv2d\n",
    "class WSConv2d(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, gain=2\n",
    "    ):\n",
    "        super(WSConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.scale = (gain / (in_channels * (kernel_size ** 2))) ** 0.5\n",
    "        self.bias = self.conv.bias\n",
    "        self.conv.bias = None\n",
    "\n",
    "        # initialize conv layer\n",
    "        nn.init.normal_(self.conv.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "        \n",
    "        self.weight=self.conv.weight\n",
    "    def forward(self, x):\n",
    "        return self.conv(x * self.scale) + self.bias.view(1, self.bias.shape[0], 1, 1)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_batchnorm=True):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.use_bn = use_batchnorm\n",
    "        #self.conv1 = nn.Conv2d(in_channels, out_channels,kernel_size=3, stride=1, padding=1)\n",
    "        #self.conv2 = nn.Conv2d(out_channels, out_channels,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv1 = WSConv2d(in_channels, out_channels)\n",
    "        self.conv2 = WSConv2d(out_channels, out_channels)\n",
    "        self.leaky = nn.LeakyReLU(0.2)\n",
    "        self.bn = nn.BatchNorm2d(out_channels,momentum=0.8)\n",
    "        \n",
    "        self.weight=self.conv1.weight\n",
    "    def forward(self, in_feature, skip):\n",
    "        x=torch.cat([in_feature, skip], 1)\n",
    "        x = self.leaky(self.conv1(x))\n",
    "        x = self.bn(x) if self.use_bn else x\n",
    "        x = self.leaky(self.conv2(x))\n",
    "        x = self.bn(x) if self.use_bn else x\n",
    "        return x    \n",
    "\n",
    "# convolution block in decoder\n",
    "class UpConv(nn.Module):\n",
    "    def __init__(self,in_channels , out_channels, use_batchnorm=True):\n",
    "        super(UpConv, self).__init__()\n",
    "        self.conv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        self.leaky = nn.LeakyReLU(0.2,inplace=True)\n",
    "        self.use_bn=use_batchnorm\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.weight=self.conv.weight\n",
    "    def forward(self,in_feature,skip):\n",
    "        x=torch.cat([in_feature, skip], 1)\n",
    "        d = self.conv(x)\n",
    "        if self.use_bn:\n",
    "            d = self.bn(d)\n",
    "        d = self.leaky(d)\n",
    "        return d    \n",
    "\n",
    "#convolution block in encoder\n",
    "class DownConv(nn.Module):\n",
    "    def __init__(self,in_channels , out_channels, use_batchnorm=True):\n",
    "        super(DownConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        self.leaky = nn.LeakyReLU(0.2,inplace=True)\n",
    "        self.use_bn=use_batchnorm\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.weight=self.conv.weight\n",
    "    def forward(self,in_feature):\n",
    "        d = self.conv(in_feature)\n",
    "        if self.use_bn:\n",
    "            d = self.bn(d)\n",
    "        d = self.leaky(d)\n",
    "        return d\n",
    "    \n",
    "##############################\n",
    "# Progressive Generator\n",
    "#############################\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels=3, out_channels=1, max_channels=512, ngf=64):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.down1=DownConv(in_channels, ngf, False)\n",
    "        self.down2=DownConv(ngf, 2*ngf)\n",
    "        self.down3=DownConv(2*ngf, 4*ngf)\n",
    "        self.down4=DownConv(4*ngf, 8*ngf)\n",
    "        self.down5=DownConv(8*ngf, 8*ngf)\n",
    "        self.down6=DownConv(8*ngf, 8*ngf)\n",
    "        self.down7=DownConv(8*ngf, 8*ngf, False)\n",
    "        \n",
    "        factors=[0.5,0.5,0.25,0.25,0.25,0.25]\n",
    "        in_cns=[1024,1024,1024,512,256,128]\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.ConvTranspose2d(max_channels, max_channels, kernel_size=4, stride=2,padding=1, bias=True),\n",
    "            nn.BatchNorm2d(max_channels,momentum=0.8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(max_channels, max_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(max_channels,momentum=0.8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "        self.initial_out = nn.Conv2d(\n",
    "            max_channels, out_channels, kernel_size=1, stride=1, padding=0\n",
    "        )\n",
    "        self.prog_blocks, self.out_layers = (\n",
    "            #nn.ModuleList([ConvBlock(2*max_channels, 2*max_channels)]),\n",
    "            nn.ModuleList([]),\n",
    "            nn.ModuleList([self.initial_out]),\n",
    "        )\n",
    "        \n",
    "        \n",
    "        for i in range(len(factors)):  \n",
    "            conv_in_c = int(in_cns[i])\n",
    "            conv_out_c = int(in_cns[i] * factors[i])\n",
    "            #self.prog_blocks.append(ConvBlock(conv_in_c, conv_out_c))\n",
    "            self.prog_blocks.append(UpConv(conv_in_c, conv_out_c))\n",
    "            self.out_layers.append(\n",
    "                nn.Conv2d(conv_out_c, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "            )\n",
    "        \n",
    "    def fade_in(self, alpha, upscaled, generated):\n",
    "        # alpha should be scalar within [0, 1], and upscale.shape == generated.shape\n",
    "        return torch.tanh(alpha * generated + (1 - alpha) * upscaled)\n",
    "    \n",
    "    def forward(self, x, steps=5, alpha=1e-5, gf=64):\n",
    "        #print(\"steps:\",steps)\n",
    "        steps=int(steps)\n",
    "        \n",
    "        # Downsampling\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        ds = [d6, d5, d4, d3, d2, d1]   \n",
    "\n",
    "        out = self.initial(d7)\n",
    "\n",
    "        for step in range(int(steps+1)):\n",
    "            upscaled = F.interpolate(out, scale_factor=2, mode=\"nearest\")\n",
    "            #out = self.prog_blocks[step](upscaled,ds[step+1])\n",
    "            out = self.prog_blocks[step](out,ds[step])\n",
    "            \n",
    "        '''if steps == len(self.prog_blocks):\n",
    "            upscaled = F.interpolate(out, scale_factor=2, mode=\"nearest\")\n",
    "            #out = Conv2D(channels, kernel_size=3, strides=1, padding=1)(upscaled)\n",
    "            out = nn.ConvTranspose2d(in_cns[-1]*factors[-1], kernel_size=4, stride=2, padding=1)(out)\n",
    "            d = nn.BatchNorm2d(momentum=0.8)(out)\n",
    "            d = nn.LeakyReLU(alpha=0.2,inplace=True)(out)'''\n",
    "\n",
    "        final_upscaled = self.out_layers[steps](upscaled)\n",
    "        final_out = self.out_layers[steps+1](out)\n",
    "        return self.fade_in(alpha, final_upscaled, final_out)\n",
    "\n",
    "##############################\n",
    "#        Discriminator\n",
    "##############################\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, dropout=0.5):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
    "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalization:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            # layers.append(nn.Dropout(dropout))\n",
    "            return layers\n",
    "\n",
    "        self.main_model = nn.Sequential(\n",
    "            *discriminator_block(in_channels + 1, 64, normalization=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.rest_model = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0)\n",
    "        )\n",
    "\n",
    "    def forward(self, img_A, img_B, matching=False):\n",
    "        # Concatenate image and condition image by channels to produce input_img\n",
    "        input_img = torch.cat((img_A, img_B), 1)\n",
    "        # print(input_img.size())\n",
    "        D_feature = self.main_model(input_img)\n",
    "        output = self.rest_model(D_feature)\n",
    "        if(matching is True):\n",
    "            return output, D_feature\n",
    "        else:\n",
    "            return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70046644",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe35e83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prog_epochs=[20,40,40,100,100,parameters['n_epochs']]\n",
    "\n",
    "# training dataloader\n",
    "def get_loader_train(image_size):\n",
    "    transform_resize = [transforms.Resize((image_size, image_size))]\n",
    "    print(transform_resize)\n",
    "    loader = DataLoader(\n",
    "        ImageDataset(parameters[\"input_path\"], transforms_=transform_resize),\n",
    "        batch_size=parameters['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=parameters['n_cpu'],\n",
    "    )\n",
    "    return loader\n",
    "def get_loader_test(image_size):\n",
    "    transform_resize = [transforms.Resize((image_size, image_size))]\n",
    "    print(transform_resize)\n",
    "    loader = DataLoader(\n",
    "        ImageDataset(parameters[\"test_path\"], transforms_=transform_resize, mode=\"test\"),\n",
    "        batch_size=8,\n",
    "        shuffle=True,\n",
    "        num_workers=parameters['n_cpu'],\n",
    "    )\n",
    "    return loader\n",
    "'''dataloader = DataLoader(\n",
    "    ImageDataset(parameters[\"input_path\"], transforms_=transforms_),\n",
    "    batch_size=parameters['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=parameters['n_cpu'],\n",
    ")'''\n",
    "# testing dataloader\n",
    "'''dataloader_test = DataLoader(\n",
    "    ImageDataset(parameters[\"test_path\"], transforms_=[],mode=\"test\"),\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=parameters['n_cpu'],\n",
    ")'''\n",
    "\n",
    "# Tensor type\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "# Calculate output of image discriminator (PatchGAN)\n",
    "patch = (1, 10, 10)\n",
    "# the output size of the patch GAN is calculated by hand,check goodnote-草稿\n",
    "use_dropout = True\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "# generator = GeneratorUNet()\n",
    "generator = Generator().to(device)\n",
    "# generator = ResnetGenerator(input_nc=1, output_nc=1).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "summary(generator,(3,128,128))\n",
    "#summary(discriminator,[(3,128,128),(1,128,128)])\n",
    "\n",
    "load_id=161\n",
    "# initialize parameters\n",
    "if parameters['start_epoch'] != 0:\n",
    "    # Load pretrained models\n",
    "    generator.load_state_dict(torch.load(\n",
    "        \"saved_models/CIT-{}/generator_{}.pth\".format(load_id,parameters['start_epoch']-1)))\n",
    "    discriminator.load_state_dict(torch.load(\n",
    "        \"saved_models/CIT-{}/discriminator_{}.pth\".format(load_id,parameters['start_epoch']-1)))\n",
    "else:\n",
    "    # Initialize weights\n",
    "    generator.apply(weights_init_normal)\n",
    "    discriminator.apply(weights_init_normal)\n",
    "    \n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=parameters['g_lr'], betas=(parameters['b1'], parameters['b2']))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=parameters['d_lr'], betas=(parameters['b1'], parameters['b2']))\n",
    "\n",
    "scheduler_G = get_scheduler(optimizer_G, parameters['scheduler'])\n",
    "scheduler_D = get_scheduler(optimizer_D,parameters['scheduler'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9c62e8",
   "metadata": {},
   "source": [
    "## loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff60a05f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# water mask loss function\n",
    "class MaskLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskLoss, self).__init__()\n",
    "    def forward(self, img, mask):\n",
    "        return torch.sum((img*0.5+0.5)*(mask*0.5+0.5)/(128*128))\n",
    "\n",
    "\n",
    "# Loss functions\n",
    "if parameters['gan_loss'] == \"mse\":\n",
    "    criterion_GAN = torch.nn.MSELoss(reduction=\"mean\").to(device)\n",
    "elif parameters['gan_loss'] ==\"bce\":\n",
    "    criterion_GAN = torch.nn.BCEWithLogitsLoss(reduction=\"mean\").to(device)\n",
    "criterion_pixelwise = torch.nn.L1Loss().to(device)\n",
    "criterion_water = MaskLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f4e1f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24ae736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################\n",
    "#  Training\n",
    "################\n",
    "prev_time = time.time()\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "n_steps=int(np.log2(parameters['img_size'] / 2))\n",
    "step=0\n",
    "for num_epochs in prog_epochs:\n",
    "    alpha = 1e-5  # start with very low alpha\n",
    "    dataloader = get_loader_train(4 * 2 ** step)\n",
    "    dataloader_test = get_loader_test(4 * 2 ** step)\n",
    "    print(f\"Current image size: {4 * 2 ** step}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            # Model input_imgs\n",
    "            input_img = batch[\"input_img\"].cuda()\n",
    "            label = batch[\"label\"].cuda()\n",
    "            mask = batch[\"mask\"].cuda()\n",
    "            \n",
    "            # Adversarial ground truths\n",
    "            valid = Tensor(np.ones((input_img.size(0), *patch))).cuda()\n",
    "            fake = Tensor(np.zeros((input_img.size(0), *patch))).cuda()\n",
    "\n",
    "            fake_img = generator(input_img,step,alpha).cuda()\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "            if step==n_steps-1:\n",
    "                optimizer_D.zero_grad()\n",
    "\n",
    "                # Real loss\n",
    "                pred_real = discriminator(label, input_img)\n",
    "                loss_real = criterion_GAN(pred_real, valid)  # 1-D\n",
    "\n",
    "                # Fake loss\n",
    "                pred_fake = discriminator(fake_img.detach(), input_img)\n",
    "                loss_fake = criterion_GAN(pred_fake, fake)  # D\n",
    "\n",
    "                # Total loss\n",
    "                loss_D = (loss_real + loss_fake) * 0.5\n",
    "\n",
    "                loss_D.backward()\n",
    "                optimizer_D.step()\n",
    "\n",
    "            # ------------------\n",
    "            #  Train Generators\n",
    "            # ------------------\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            # Pixel-wise loss\n",
    "            loss_pixel = criterion_pixelwise(fake_img, label)\n",
    "            if step==n_steps-1:\n",
    "                # GAN loss\n",
    "                pred_fake = discriminator(fake_img, input_img)\n",
    "                \n",
    "                loss_GAN = criterion_GAN(pred_fake, valid)  # 1-D\n",
    "                # water constrain loss\n",
    "                loss_water = criterion_water(fake_img, mask)\n",
    "                loss_G = (loss_GAN + loss_pixel * parameters['pixel_lamda']+100*loss_water)\n",
    "            else:\n",
    "                loss_G = (loss_pixel * parameters['pixel_lamda'])\n",
    "            # print(loss_GAN,loss_pixel)\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            #===============\n",
    "            # training debug\n",
    "            #---------------\n",
    "            if parameters[\"debug\"]==True:\n",
    "                fake_img = generator(input_img).cuda()\n",
    "                imgs_error_test = torch.cat((fake_img.detach()*0.5+0.5, label*0.5+0.5, (fake_img.detach()-label)*0.5+0.5), dim=0).cpu()\n",
    "                c=3\n",
    "                r=5\n",
    "                fig =plt.figure(dpi=200,figsize=(c,r),facecolor=\"white\",linewidth=0)\n",
    "                #axs = plt.subplots(r, c)\n",
    "                for col in range(c):\n",
    "                    for row in range(r):\n",
    "                        axs=plt.subplot(r,c,c*row+col+1)\n",
    "                        #axs.tick_params(axis=u'both', which=u'both',length=0,labelsize=5)\n",
    "                        plt.xticks([])\n",
    "                        plt.yticks([])\n",
    "                        plt.imshow(np.transpose((imgs_error_test[parameters['batch_size']*col+row]),(1,2,0)))\n",
    "                        #axs.set_title(titles[i])\n",
    "                        #axs.axis('off')\n",
    "                plt.subplots_adjust(wspace=0.0,hspace=0.05)\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "            \n",
    "            # --------------\n",
    "            #  Log Progress\n",
    "            # --------------\n",
    "            if step==n_steps-1:\n",
    "                # Determine approximate time left\n",
    "                batches_done = epoch * len(dataloader) + i\n",
    "                batches_left = parameters[\"n_epochs\"] * len(dataloader) - batches_done\n",
    "                time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n",
    "                prev_time = time.time()\n",
    "                # Print log\n",
    "                sys.stdout.write(\n",
    "                    \"\\r[Epoch %d/%d][Batch %d/%d][min: %f][D loss: %f] [G loss: %f, pixel: %f, GAN: %f, mask: %f] ETA: %s\"\n",
    "                    % (\n",
    "                        epoch,\n",
    "                        parameters[\"n_epochs\"],\n",
    "                        i,\n",
    "                        len(dataloader),\n",
    "                        fake_img.detach().min().item(),\n",
    "                        loss_D.item(),\n",
    "                        loss_G.item(),\n",
    "                        loss_pixel.item(),\n",
    "                        loss_GAN.item(),\n",
    "                        loss_water.item(),\n",
    "                        time_left,\n",
    "                    )\n",
    "                )\n",
    "                if neptune_log:\n",
    "                    run[\"train/Dloss\"].log(loss_D.item())\n",
    "                    run[\"train/Gloss\"].log(loss_G.item())\n",
    "                    run[\"train/pixelloss\"].log(loss_pixel.item())\n",
    "                    run[\"train/GANloss\"].log(loss_GAN.item())\n",
    "                    run[\"train/lr\"].log(scheduler_G.get_last_lr()[0])\n",
    "                G_losses.append(loss_G.item())\n",
    "                D_losses.append(loss_D.item())\n",
    "                # Show Results\n",
    "                if ((epoch % 10 == 0) or (epoch == parameters[\"n_epochs\"] - 1)) and (i == len(dataloader) - 1):\n",
    "                    ShowResults(generator, dataloader_test, step, \"train\")\n",
    "\n",
    "                # progress scheduler\n",
    "                scheduler_G.step()\n",
    "                scheduler_D.step()\n",
    "                # save generated results\n",
    "                if neptune_log and (((epoch == parameters[\"n_epochs\"] - 1) and (i == len(dataloader) - 1)) or (epoch%parameters['checkpoint_interval']==5)):  \n",
    "                    #save images\n",
    "                    os.makedirs(\"images/%s/%d\" % (run['sys/id'].fetch(),epoch), exist_ok=True)\n",
    "                    for j, test_batch in enumerate(dataloader_test):\n",
    "                        test_input_img = test_batch[\"input_img\"].cuda()\n",
    "                        test_label = 0.5* test_batch[\"label\"]+0.5\n",
    "                        test_dem=test_batch[\"dem\"]*0.5+0.5\n",
    "                        test_water=test_batch[\"mask\"]*0.5+0.5\n",
    "                        with torch.no_grad():\n",
    "                            fake = 0.5* generator(test_input_img).detach().cpu()+0.5\n",
    "                        for k in range(test_label.shape[0]):\n",
    "                            vutils.save_image(test_label[k],\"./images/%s/%d/%s_%s.png\"%(run['sys/id'].fetch(),epoch,test_batch['name'][k],'builtarea'))\n",
    "                            vutils.save_image(fake[k],\"./images/%s/%d/%s_%s.png\"%(run['sys/id'].fetch(), epoch,test_batch['name'][k],'output'))\n",
    "                            vutils.save_image(test_dem[k],\"./images/%s/%d/%s_%s.png\"%(run['sys/id'].fetch(),epoch,test_batch['name'][k],'dem'))\n",
    "                            vutils.save_image(test_water[k],\"./images/%s/%d/%s_%s.png\"%(run['sys/id'].fetch(),epoch,test_batch['name'][k],'water'))\n",
    "                    # Save model checkpoints\n",
    "\n",
    "                    torch.save(generator.state_dict(), \"saved_models/%s/generator_%d.pth\" % (run['sys/id'].fetch(), epoch))\n",
    "                    torch.save(discriminator.state_dict(), \"saved_models/%s/discriminator_%d.pth\" % (run['sys/id'].fetch(), epoch))\n",
    "            else:\n",
    "                batches_done = epoch * len(dataloader) + i\n",
    "                batches_left = prog_epochs[step] * len(dataloader) - batches_done\n",
    "                # Print log\n",
    "                sys.stdout.write(\n",
    "                    \"\\r[Step: %i][Epoch %d/%d][Batch %d/%d][min: %f][Loss:%f]\"\n",
    "                    % (\n",
    "                        step,\n",
    "                        epoch,\n",
    "                        prog_epochs[step],\n",
    "                        i,\n",
    "                        len(dataloader),\n",
    "                        fake_img.detach().min().item(),\n",
    "                        loss_G.item(),\n",
    "                    )\n",
    "                )\n",
    "                if neptune_log:\n",
    "                    run[\"train/pixelloss\"].log(loss_G.item())\n",
    "                if ((epoch % 10 == 0) or (epoch == parameters[\"n_epochs\"] - 1)) and (i == len(dataloader) - 1):\n",
    "                    ShowResults(generator, dataloader_test, step, \"train\")\n",
    "            alpha += 1 / (\n",
    "                prog_epochs[step] * len(dataloader)\n",
    "            )\n",
    "            alpha = min(alpha, 1)\n",
    "    step += 1  # progress to the next img size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58472ee-2954-4ac5-a7bf-15b8d88fd1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542ca50d-81b8-4091-bf04-8640c2dc68d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "neptune": {
   "notebookId": "726f4ece-9264-43cc-9b99-ac6eb8ee6ba8",
   "projectVersion": 2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
